{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bRvbOK2Vu6lP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import csv\n",
        "import argparse\n",
        "from functools import partial\n",
        "import itertools\n",
        "import uuid\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
        "from torchtext.vocab import GloVe\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import time\n",
        "import importlib\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "a8ppInEHu853"
      },
      "outputs": [],
      "source": [
        "# !pip install selenium\n",
        "# !pip install webdriver-manager\n",
        "# !pip install pickle5\n",
        "# !pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ_CiboAvAvm",
        "outputId": "74946f33-9706-4459-a04a-9df85754a955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Using cuda.\n"
          ]
        }
      ],
      "source": [
        "COLAB = True\n",
        "\n",
        "USE_CUDA = False\n",
        "if COLAB:\n",
        "    from google.colab import drive \n",
        "    drive.mount('/content/gdrive')\n",
        "    PATH = 'gdrive/MyDrive/nlp22/project/'\n",
        "    sys.path.append('gdrive/MyDrive/nlp22/project')\n",
        "\n",
        "    USE_CUDA = torch.cuda.is_available()\n",
        "\n",
        "    if USE_CUDA:\n",
        "        DEVICE = torch.device('cuda')\n",
        "        print(\"Using cuda.\")\n",
        "    else:\n",
        "        DEVICE = torch.device('cpu')\n",
        "        print(\"Using cpu.\")\n",
        "\n",
        "    os.chdir(os.path.join(os.getcwd(),'gdrive/MyDrive/nlp22/project'))\n",
        "\n",
        "from album_loader import *\n",
        "import lyric_loader\n",
        "import nlpmodel\n",
        "importlib.reload(nlpmodel)\n",
        "\n",
        "# VECTORS_CACHE_DIR = './.vector_cache'\n",
        "\n",
        "UNK, PAD, LBS, LBE, SBS, SBE, PART = 0, 1, 2, 3, 4, 5, 6\n",
        "FIRST_TOKENS = 5000\n",
        "STRATEGY = f'FIRST {FIRST_TOKENS} - Embeddings On'\n",
        "EMBEDDING_DIMENSIONS = 300\n",
        "\n",
        "RATE_TYPE = 'c_rate'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wtVw3Y2vO5G",
        "outputId": "3ff14b5e-e152-4a47-bbd8-ac776aaa1a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git-lfs is already the newest version (2.3.4-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt install git-lfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW9G_2civLoA",
        "outputId": "7d89dc46-f7a7-415f-ff8e-1cd042c4472f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4.21.1\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6VX2NWSQ65-_"
      },
      "outputs": [],
      "source": [
        "def init_albums(path, file, standardize_parts, see_lbs):\n",
        "    \"\"\"\n",
        "    Instantiates a set of Albums for regression purposes\n",
        "\n",
        "    kwargs:\n",
        "    file  -- file containing Albums info (albums_f.pickle)\n",
        "    standardize_parts - signals whether to standardize parts in lyrics\n",
        "    standardize_parts - signals whether to see linen breaks in lyrics\n",
        "    \"\"\"\n",
        "    albums_data = os.path.join(path, file)\n",
        "    albums_pre = lyric_loader.RegAlbums(album_path = albums_data, \n",
        "                                        standardize_parts = standardize_parts, \n",
        "                                        see_line_breaks = see_lbs)\n",
        "    reg_albums = albums_pre.reg_full_album_text() \n",
        "    return reg_albums\n",
        "\n",
        "def getData(data_list, rating_type):\n",
        "    \"\"\"\n",
        "    Gets data from RegAlbums object\n",
        "\n",
        "    kwargs:\n",
        "    data_list -- dataset containing regression albums\n",
        "    rating_type - critic or user rating\n",
        "    \"\"\"\n",
        "    x = [i[3] for i in data_list]\n",
        "    if rating_type == 'c_rate':\n",
        "        y = [int(i[1]) for i in data_list]\n",
        "    else:\n",
        "        y = [int(10 * i[2]) for i in data_list]\n",
        "    return x, y\n",
        "  \n",
        "def split_datasets(reg_albums, rating_type):\n",
        "    \"\"\"\n",
        "    Splits data into train, valid, and test sets\n",
        "\n",
        "    kwargs:\n",
        "    reg_albums -- unprocessed regression albums to be split up\n",
        "    rating_type - critic or user rating\n",
        "    \"\"\"\n",
        "    num_train_valid = int(len(reg_albums) * 0.8)\n",
        "    num_test = len(reg_albums) - num_train_valid\n",
        "    train_valid_data, test_data = random_split(reg_albums, [num_train_valid, num_test])\n",
        "\n",
        "    num_train = int(num_train_valid * 0.90)\n",
        "    num_valid = num_train_valid - num_train\n",
        "    train_data, valid_data = random_split(train_valid_data, [num_train, num_valid])\n",
        "\n",
        "    x_train, y_train = getData(train_data, 'c_rate')\n",
        "    x_valid, y_valid = getData(valid_data, 'c_rate')\n",
        "    x_test, y_test = getData(test_data, 'c_rate')\n",
        "    \n",
        "    return x_train, y_train, x_valid, y_valid, x_test, y_test\n",
        "\n",
        "def create_encodings(tokenizer, text, **kwargs):\n",
        "    \"\"\"\n",
        "    Tokenize text into encdoings\n",
        "    \"\"\"\n",
        "    max_length = None\n",
        "    if 'max_length' in kwargs:\n",
        "        max_length = kwargs['max_length']\n",
        "    \n",
        "    if 'add_special_tokens' in kwargs:\n",
        "        add_special_tokens = kwargs['add_special_tokens']\n",
        "    \n",
        "    encodings = tokenizer(text, truncation=True, padding=True, \n",
        "                                max_length=max_length, add_special_tokens = add_special_tokens)\n",
        "    return encodings\n",
        "\n",
        "class MakeTorchData(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Make Dataset out of encodings to pass to HF Trainer \n",
        "    (which will conduct training)\n",
        "\n",
        "    kwargs:\n",
        "    encodings -- encodings to convert\n",
        "    labels -- response variables\n",
        "    \"\"\"\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {}\n",
        "        for k, v in self.encodings.items():\n",
        "            if torch.is_tensor(v):\n",
        "                item[k] = v[idx]\n",
        "            else:\n",
        "            item[k] = torch.tensor(v[idx])\n",
        "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
        "        item[\"labels\"] = float(item[\"labels\"])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iMmXvZ2mOci9"
      },
      "outputs": [],
      "source": [
        "\"\"\" Unused :(\"\"\"\n",
        "\n",
        "# def chunker(item, chunksize):\n",
        "#     newObs = []\n",
        "#     input_id_chunks = list(item['input_ids'].split(chunksize - 2))\n",
        "#     mask_chunks = list(item['attention_mask'].split(chunksize - 2))\n",
        "#     for i in range(len(input_id_chunks)):\n",
        "#         if input_id_chunks[i][-1].item() == 0:\n",
        "#             break\n",
        "#         input_id_chunks[i] = torch.cat([torch.tensor([101]), input_id_chunks[i], torch.tensor([102])])\n",
        "#         # add attention tokens to attention mask\n",
        "#         mask_chunks[i] = torch.cat([torch.tensor([1]), mask_chunks[i], torch.tensor([1])])\n",
        "#         # get required padding length\n",
        "#         pad_len = chunksize - input_id_chunks[i].shape[0]\n",
        "#         # check if tensor length satisfies required chunk size\n",
        "#         if pad_len > 0:\n",
        "#             # if padding length is more than 0, we must add padding\n",
        "#             input_id_chunks[i] = torch.cat([input_id_chunks[i], torch.Tensor([0] * pad_len)])\n",
        "#             mask_chunks[i] = torch.cat([mask_chunks[i], torch.Tensor([0] * pad_len)])\n",
        "#         newDictItem = {}\n",
        "#         newDictItem['input_ids'] = input_id_chunks[i]\n",
        "#         newDictItem['attention_mask'] = mask_chunks[i]\n",
        "#         newDictItem['labels'] = item['labels']\n",
        "#         newObs.append(newDictItem)\n",
        "#     return newObs\n",
        "\n",
        "# def collate_batch_into_chunks(features):\n",
        "#     newObs = []\n",
        "#     for item in features:\n",
        "#         newObs.extend(chunker(item, 512))\n",
        "#     return transformers.default_data_collator(newObs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "teX2KyQLGrCA"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def compute_metrics_for_regression(eval_pred):\n",
        "    \"\"\"\n",
        "    Compute custom metrics for regression\n",
        "    -Function automatically run and input automatically\n",
        "        supplied by HF Trainer\n",
        "\n",
        "    kwargs:\n",
        "    eval_pred -- prediction and label for evaluated dataset\n",
        "    \"\"\"\n",
        "    print(\"I am computing the metrics for regression...\")\n",
        "    print(f\"Here is the type of eval_pred input to this function {type(eval_pred)}\")\n",
        "    print(f\"Now, here is the actual value of eval_pred {eval_pred}\")\n",
        "    logits, labels = eval_pred\n",
        "    print(f\"Here is the length of logits: {len(logits)}\")\n",
        "    \n",
        "    labels = labels.reshape(-1, 1)\n",
        "\n",
        "    print(\"Logits:\", logits[0:5])\n",
        "    print(\"Labels:\", labels[0:5])\n",
        "    \n",
        "    mse = mean_squared_error(labels, logits)\n",
        "    var = np.var(labels)\n",
        "    r2 = r2_score(labels, logits)\n",
        "    \n",
        "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
        "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
        "        \n",
        "    return {\"mse\": mse, \"var\": var, \"r2\": r2, \"accuracy\" : accuracy}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_train_test(standardize_parts, see_lbs):\n",
        "    \"\"\"\n",
        "    Split into train_val, test datasets and save\n",
        "\n",
        "    kwargs:\n",
        "    standardize_parts -- standardize parts in lyrics if true, \n",
        "        else won't standardize\n",
        "    see_lbs - see line breaks in lyrics if true, else won't\n",
        "    \"\"\"\n",
        "    print(\"Create train test was called...\")\n",
        "    sp = 1 if standardize_parts else 0\n",
        "    sl = 1 if see_lbs else 0\n",
        "    u_rate_min = 10\n",
        "    reg_albums = init_albums(path = '', file = 'albums_f.pickle', \n",
        "                standardize_parts = standardize_parts, see_lbs = see_lbs, u_rate_min = u_rate_min)\n",
        "\n",
        "    fourth = len(reg_albums) // 4\n",
        "    train_val, test = random_split(reg_albums, [len(reg_albums) - fourth, fourth])\n",
        "\n",
        "    comb = (train_val, test)\n",
        "    with open(f'train_val_test_{sp}_{sl}.pickle', 'wb') as handle:\n",
        "        pickle.dump(comb, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    return comb\n",
        "\n",
        "def load_train_test(standardize_parts, see_lbs):\n",
        "    \"\"\"\n",
        "    Loads train_val data if it is already available\n",
        "\n",
        "    kwargs:\n",
        "    standardize_parts -- standardize parts in lyrics if true, \n",
        "        else won't standardize\n",
        "    see_lbs - see line breaks in lyrics if true, else won't\n",
        "    \"\"\"\n",
        "    sp = 1 if standardize_parts else 0\n",
        "    sl = 1 if see_lbs else 0\n",
        "    try:\n",
        "        with open(f'train_val_test_{sp}_{sl}.pickle', 'rb') as handle:\n",
        "            comb = pickle.load(handle)   \n",
        "    except:\n",
        "        print(f\"Creating train/val/test sets for standardize_parts: {standardize_parts}, see_lbs: {see_lbs}\")\n",
        "        comb = create_train_test(standardize_parts, see_lbs)\n",
        "    train, test = comb\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tsCs70uEnZVb"
      },
      "outputs": [],
      "source": [
        "def main(methodology, \n",
        "          methodologies, \n",
        "          tokenizer,\n",
        "          save_label,\n",
        "          max_length,\n",
        "          evaluation_strategy = 'epoch',\n",
        "          save_strategy = 'epoch',\n",
        "          save_total_limit = 1,\n",
        "          learning_rate = 5e-5,\n",
        "          per_device_train_batch_size = 16,\n",
        "          per_device_eval_batch_size = 16,\n",
        "          num_train_epochs = 20,\n",
        "          weight_decay = 0,\n",
        "          load_best_model_at_end = True,\n",
        "          metric_for_best_model = 'r2',\n",
        "          compute_metrics_for_regression = compute_metrics_for_regression,\n",
        "          collate_batch_into_chunks = collate_batch_into_chunks\n",
        "         ):\n",
        "    \n",
        "    \"\"\"\n",
        "    Runs Transformer from end-to-end, from initializing\n",
        "        Albums to supply to regression to training and \n",
        "        evaluation\n",
        "    \n",
        "    kwargs:\n",
        "    -Defined in separte cell below\n",
        "    \"\"\"\n",
        "    \n",
        "    id = uuid.uuid4()\n",
        "\n",
        "    methodology_name = methodologies[methodology][0]\n",
        "    model_name = methodologies[methodology][1]\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    tokenizer.add_tokens(['<lb>', '</lb>', '<sb>', '</sb>', '[part]'])\n",
        "\n",
        "    create_encodings_fx = methodologies[methodology][2]\n",
        "    make_datasets_fx = methodologies[methodology][3]\n",
        "    standardize_parts = methodologies[methodology][4]\n",
        "    see_lbs = methodologies[methodology][5]\n",
        "    chunk = methodologies[methodology][6]\n",
        "\n",
        "    if methodology == 0:\n",
        "        max_length = 512\n",
        "    if chunk:\n",
        "        print(\"Creating chunks so...\")\n",
        "        max_length = 40000\n",
        "        per_device_eval_batch_size = 1\n",
        "    else:\n",
        "        collate_batch_into_chunks = None\n",
        "    \n",
        "    print(f\"Max length is now {max_length}\")\n",
        "    print(f\"Collate function is now {collate_batch_into_chunks}\")\n",
        "    \n",
        "    print(f\"Running following model: {methodology_name}\")\n",
        "    print(f\"Methodology: {methodology_name}\")\n",
        "    print(f\"Create encodings function: {create_encodings_fx}\")\n",
        "    print(f\"Standardize parts: {standardize_parts}\")\n",
        "    print(f\"See line breaks: {see_lbs}\")\n",
        "    print(f\"Chunking: {chunk}\")\n",
        "\n",
        "    reg_albums, test_reg_albums = load_train_test(standardize_parts, see_lbs)\n",
        "    print(f\"Working with {len(reg_albums)} albums in total for reg_albums...\")\n",
        "    \n",
        "\n",
        "    x_train, y_train, x_valid, y_valid, x_test, y_test = split_datasets(reg_albums, 'c_rate')\n",
        "    \n",
        "\n",
        "    print(\"Creating train encodings...\")\n",
        "    train_encodings = create_encodings_fx(tokenizer, x_train, max_length = max_length, add_special_tokens = False)\n",
        "    print(\"Creating valid encodings...\")\n",
        "    valid_encodings = create_encodings_fx(tokenizer, x_valid, max_length = max_length, add_special_tokens = False)\n",
        "    print(\"Creating test encodings...\")\n",
        "    test_encodings = create_encodings_fx(tokenizer, x_test, max_length = max_length, add_special_tokens = False)\n",
        "    \n",
        "    train_dataset = make_datasets_fx(train_encodings, y_train)\n",
        "    valid_dataset = make_datasets_fx(valid_encodings, y_valid)\n",
        "    test_dataset =  make_datasets_fx(test_encodings, y_test)\n",
        "    \n",
        "    print(train_dataset[0])\n",
        "    print(len(train_dataset[0]['input_ids']))\n",
        "    f\"{save_label}/test_dataset\"\n",
        "    print(f\"After creating the datasets, the length of the training set is: {len(train_dataset)}\")\n",
        "    print(f\"The length of the validation set is: {len(valid_dataset)}\")\n",
        "    print(f\"The length of the test set is: {len(test_dataset)}\")\n",
        "        \n",
        "    print(\"Finalized dataset creation, moving on to model...\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 1, ignore_mismatched_sizes = True) # np.log(1000)\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model = model.cuda()\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        f\"./{save_label}\",\n",
        "        evaluation_strategy = evaluation_strategy,\n",
        "        save_strategy = save_strategy,\n",
        "        save_total_limit = save_total_limit,\n",
        "        learning_rate = learning_rate,\n",
        "        per_device_train_batch_size=per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=per_device_eval_batch_size,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        weight_decay=weight_decay,\n",
        "        load_best_model_at_end=load_best_model_at_end,\n",
        "        metric_for_best_model=metric_for_best_model\n",
        "    )\n",
        "    info = [model_name, learning_rate, per_device_train_batch_size, per_device_eval_batch_size, num_train_epochs]\n",
        "    \n",
        "    print(collate_batch_into_chunks)\n",
        "    print(\"Instantiating the Trainer...\")\n",
        "    # # Call the Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,                         # the instantiated Transformers model to be trained\n",
        "        args=args,                  # training arguments, defined above\n",
        "        train_dataset=train_dataset,         # training dataset\n",
        "        eval_dataset=valid_dataset,          # evaluation dataset\n",
        "        data_collator = collate_batch_into_chunks,\n",
        "        compute_metrics=compute_metrics_for_regression    # the callback that computes metrics of interest\n",
        "    )\n",
        "\n",
        "    print(\"Training the model...\")\n",
        "    # # # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    print(\"Evaluating the model using evaluation dataset...\")\n",
        "    # # Call the summary\n",
        "    a = trainer.evaluate()\n",
        "    print(\"Returned from evaluate on evaluation set...\")\n",
        "    print(type(a))\n",
        "    print(a)\n",
        "\n",
        "    print(\"Evaluating the model using test dataset...\")\n",
        "    b = trainer.evaluate(test_dataset)\n",
        "    print(\"Returned from evaluate on test set...\")\n",
        "    print(type(b))\n",
        "    print(bin)\n",
        "    return a, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5WTdHsSF_uV9"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TNNNVC0s5s_a",
        "outputId": "0a35c86f-4d23-44ad-b810-7f6d4e1e8c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max length is now 512\n",
            "Collate function is now None\n",
            "Running following model: BERT First 512\n",
            "Methodology: BERT First 512\n",
            "Create encodings function: <function create_encodings at 0x7ff743716a70>\n",
            "Standardize parts: True\n",
            "See line breaks: False\n",
            "Chunking: False\n",
            "After making limitations, working with 2856 albums in total...\n",
            "2814/2856 (98.5%) albums, have length >200 and are retained.\n",
            "Creating train encodings...\n",
            "Creating valid encodings...\n",
            "Creating test encodings...\n",
            "{'input_ids': tensor([30524,  4873,  2058,  1996, 10098,  1010,  2126,  2039,  2152,  2045,\n",
            "         1005,  1055,  1037,  2455,  2008,  1045,  2657,  1997,  2320,  1999,\n",
            "         1037, 29149,  4873,  2058,  2008, 10098,  1010, 15717,  2024,  2630,\n",
            "         1998,  1996,  5544,  2008,  2017,  8108,  2000,  3959,  2428,  2079,\n",
            "         2272,  2995, 13834,  1045,  1005,  2222,  4299,  2588,  1037,  2732,\n",
            "         1998,  5256,  2039,  2073,  1996,  8044,  2024,  2521,  2369,  2033,\n",
            "         2073, 13460, 14899,  2066, 14380,  9010,  2152,  2682,  1996, 17321,\n",
            "        13284,  1010,  2008,  1005,  1055,  2073,  2017,  1005,  2222,  2424,\n",
            "         2033,  4873,  2058,  1996, 10098,  1010,  2630, 12887,  4875,  5055,\n",
            "         4875,  2058,  2008, 10098,  2339,  1010,  2821,  2339,  1010,  2064,\n",
            "         1005,  1056,  1045,  1029,  2065,  3407,  2210,  2630, 12887,  4875,\n",
            "         3458,  1996, 10098,  2339,  1010,  2821,  2339,  1010,  2064,  1005,\n",
            "         1056,  1045,  1029, 30525, 30524,  2043,  2017,  1005,  2128,  5629,\n",
            "         2043,  2017,  1005,  2128,  5629,  1996,  2878,  2088,  8451,  2007,\n",
            "         2017,  2043,  2017,  1005,  2128,  5870,  2043,  2017,  1005,  2128,\n",
            "         5870,  1996,  3103,  3310,  9716,  2083,  2021,  2043,  2017,  1005,\n",
            "         2128,  6933,  2017,  3288,  2006,  1996,  4542,  2061,  2644,  2008,\n",
            "        19381,  2022,  3407,  2153,  2043,  2017,  1005,  2128,  5629,  2562,\n",
            "         2006,  5629,  1996,  2878,  2088,  8451,  2007,  2017,  2065,  2017,\n",
            "         3402,  2424,  2041,  2017,  1005,  2310,  2042, 11703,  7416,  7178,\n",
            "         2123,  1005,  1056,  2131, 21392,  7178,  2065,  2115,  3129, 14969,\n",
            "         2135,  4136,  2017,  2017,  1005,  2128,  2205, 18890,  2123,  1005,\n",
            "         1056,  2017, 13433,  4904,  1998,  2005,  6014,  1005,  1055,  8739,\n",
            "         2015,  9279,  1037,  5475, 21745,  2065,  1037,  8872,  7365,  2039,\n",
            "         1998,  2398,  2017,  1037,  4942,  6873,  8189,  2065,  1996, 18087,\n",
            "         2323,  2202,  1037,  9898,  2096,  2017,  1005,  2128, 10998,  2091,\n",
            "         1996, 12485,  2123,  1005,  1056, 27874,  1998, 13673,  2138,  2002,\n",
            "         1005,  1055, 10676,  2074,  2227,  1996,  2088,  1998,  2868,  1005,\n",
            "         3426,  2043,  2017,  1005,  2128,  5390,  2378,  1005,  2123,  1005,\n",
            "         1056,  2017,  2113,  2008,  2115,  2191,  1011,  2039,  4627,  2000,\n",
            "         2448,  1998,  2115,  2159,  2131,  2417,  1998, 15121,  7685,  5293,\n",
            "         2115, 13460,  2031,  4426,  1037,  2210,  4569,  2031,  1037,  3608,\n",
            "         5293,  2009,  2035,  5293,  2115, 13460,  2272,  2006,  2131,  3407,\n",
            "         2043,  2017,  1005,  2128,  5629,  1005,  3426,  2043,  2017,  1005,\n",
            "         2128,  5629,  1996,  2878,  2088,  8451,  2007,  2017, 30525, 30524,\n",
            "         2054,  1037,  2154,  2023,  2038,  2042,  2054,  1037,  4189,  6888,\n",
            "         1045,  1005,  1049,  1999,  2339,  2009,  1005,  1055,  2471,  2066,\n",
            "        21388,  2078,  1005,  1999,  2293,  2045,  1005,  1055,  1037,  2868,\n",
            "         2006,  2026,  2227,  2005,  1996,  2878,  2529,  2679,  2339,  2009,\n",
            "         1005,  1055,  2471,  2066, 21388,  2078,  1005,  1999,  2293,  2035,\n",
            "         1996,  2189,  1997,  2166,  3849,  2000,  2022,  2066,  1037,  4330,\n",
            "         2008,  2003,  3614,  2378,  1005,  2005,  2033,  1998,  2013,  1996,\n",
            "         2126,  2008,  1045,  2514,  2043,  2008,  4330,  4627,  2000, 14113,\n",
            "         1045,  2071,  2425,  1045,  2001,  4634,  1045,  2052,  8415,  1045,\n",
            "         2001,  4634,  2009,  1005,  1055,  2471,  2066,  2108,  1999,  2293,\n",
            "         2471,  2066,  2108,  1999,  2293,  2009,  1005,  1055,  2471,  2009,\n",
            "         1005,  1055,  2471,  2021,  2023,  2064,  1005,  1056,  2022,  2293,\n",
            "         2138,  1045,  2514,  2061,  2092,  2053, 21503,  1010,  2053, 14038,\n",
            "         2015,  1010,  2053, 19906,  2023,  2064,  1005,  1056,  2022,  2293,\n",
            "         1010,  1045,  2131,  2053, 14849, 11750,  2026,  2132,  2003,  2025,\n",
            "         1999,  1996,  3712,  2026,  2540,  2515,  2025,  3233,  2145,  2963,\n",
            "         2009,  3786]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1]), 'labels': 69.0}\n",
            "512\n",
            "After creating the datasets, the length of the training set is: 2055\n",
            "The length of the validation set is: 229\n",
            "The length of the test set is: 572\n",
            "Finalized dataset creation, moving on to model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized because the shapes did not match:\n",
            "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([1, 768]) in the model instantiated\n",
            "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2055\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1290\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Instantiating the Trainer...\n",
            "Training the model...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1290' max='1290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1290/1290 17:20, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Mse</th>\n",
              "      <th>Var</th>\n",
              "      <th>R2</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2857.026123</td>\n",
              "      <td>2857.025635</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>-32.615396</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>895.021301</td>\n",
              "      <td>895.021301</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>-9.530704</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>86.924179</td>\n",
              "      <td>86.924179</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>-0.022739</td>\n",
              "      <td>0.034934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1705.524600</td>\n",
              "      <td>87.243263</td>\n",
              "      <td>87.243263</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>-0.026493</td>\n",
              "      <td>0.039301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1705.524600</td>\n",
              "      <td>99.849922</td>\n",
              "      <td>99.849922</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>-0.174821</td>\n",
              "      <td>0.039301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1705.524600</td>\n",
              "      <td>84.505058</td>\n",
              "      <td>84.505066</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>0.005724</td>\n",
              "      <td>0.061135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1705.524600</td>\n",
              "      <td>73.217690</td>\n",
              "      <td>73.217690</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>0.138530</td>\n",
              "      <td>0.069869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>65.864300</td>\n",
              "      <td>77.713051</td>\n",
              "      <td>77.713066</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>0.085638</td>\n",
              "      <td>0.078603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>65.864300</td>\n",
              "      <td>84.941544</td>\n",
              "      <td>84.941544</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>0.000589</td>\n",
              "      <td>0.056769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>65.864300</td>\n",
              "      <td>86.963882</td>\n",
              "      <td>86.963882</td>\n",
              "      <td>84.991592</td>\n",
              "      <td>-0.023206</td>\n",
              "      <td>0.048035</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6ac5cc750>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[21.256742]\n",
            " [21.223179]\n",
            " [21.253834]\n",
            " [21.254168]\n",
            " [21.260906]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-129\n",
            "Configuration saved in ./BERT First 512/checkpoint-129/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-129/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-1161] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6ac8e9c10>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[45.45079 ]\n",
            " [45.42547 ]\n",
            " [45.443764]\n",
            " [45.443398]\n",
            " [45.44888 ]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-258\n",
            "Configuration saved in ./BERT First 512/checkpoint-258/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-258/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-1290] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6acb08850>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[72.51901 ]\n",
            " [72.5089  ]\n",
            " [72.5209  ]\n",
            " [72.51377 ]\n",
            " [72.516205]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-387\n",
            "Configuration saved in ./BERT First 512/checkpoint-387/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-387/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-129] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6c4070650>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[75.42979]\n",
            " [75.28631]\n",
            " [75.44517]\n",
            " [75.41584]\n",
            " [75.42215]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-516\n",
            "Configuration saved in ./BERT First 512/checkpoint-516/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-516/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-258] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6ac5cc650>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[78.222435]\n",
            " [78.190125]\n",
            " [78.20078 ]\n",
            " [77.93885 ]\n",
            " [78.206024]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-645\n",
            "Configuration saved in ./BERT First 512/checkpoint-645/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-645/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-516] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6acb44190>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[78.97354 ]\n",
            " [78.958046]\n",
            " [78.988106]\n",
            " [74.543045]\n",
            " [78.65009 ]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-774\n",
            "Configuration saved in ./BERT First 512/checkpoint-774/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-774/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-387] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6ac486150>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[79.31385 ]\n",
            " [78.992775]\n",
            " [77.894295]\n",
            " [69.9058  ]\n",
            " [77.29882 ]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-903\n",
            "Configuration saved in ./BERT First 512/checkpoint-903/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-903/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-645] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6ac6cd350>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[80.841286]\n",
            " [81.27626 ]\n",
            " [79.87078 ]\n",
            " [75.67984 ]\n",
            " [77.749405]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-1032\n",
            "Configuration saved in ./BERT First 512/checkpoint-1032/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-1032/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-774] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6acad5d90>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[82.16741]\n",
            " [82.14816]\n",
            " [80.70864]\n",
            " [75.42825]\n",
            " [78.80461]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-1161\n",
            "Configuration saved in ./BERT First 512/checkpoint-1161/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-1161/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-1032] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6acbc9550>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[82.438194]\n",
            " [82.37202 ]\n",
            " [80.2937  ]\n",
            " [75.64771 ]\n",
            " [78.10065 ]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to ./BERT First 512/checkpoint-1290\n",
            "Configuration saved in ./BERT First 512/checkpoint-1290/config.json\n",
            "Model weights saved in ./BERT First 512/checkpoint-1290/pytorch_model.bin\n",
            "Deleting older checkpoint [BERT First 512/checkpoint-1161] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./BERT First 512/checkpoint-903 (score: 0.13853022414011906).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 229\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating the model using evaluation dataset...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 572\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6acb249d0>\n",
            "Here is the length of logits: 229\n",
            "Logits: [[79.31385 ]\n",
            " [78.992775]\n",
            " [77.894295]\n",
            " [69.9058  ]\n",
            " [77.29882 ]]\n",
            "Labels: [[85.]\n",
            " [61.]\n",
            " [85.]\n",
            " [79.]\n",
            " [76.]]\n",
            "Returned from evaluate on evaluation set...\n",
            "<class 'dict'>\n",
            "{'eval_loss': 73.21768951416016, 'eval_mse': 73.21768951416016, 'eval_var': 84.99159240722656, 'eval_r2': 0.13853022414011906, 'eval_accuracy': 0.06986899563318777, 'eval_runtime': 3.7872, 'eval_samples_per_second': 60.466, 'eval_steps_per_second': 3.961, 'epoch': 10.0}\n",
            "Evaluating the model using test dataset...\n",
            "I am computing the metrics for regression...\n",
            "Here is the type of eval_pred input to this function <class 'transformers.trainer_utils.EvalPrediction'>\n",
            "Now, here is the actual value of eval_pred <transformers.trainer_utils.EvalPrediction object at 0x7ff6acb34a90>\n",
            "Here is the length of logits: 572\n",
            "Logits: [[66.87273 ]\n",
            " [78.05265 ]\n",
            " [65.40853 ]\n",
            " [71.547035]\n",
            " [73.48673 ]]\n",
            "Labels: [[79.]\n",
            " [73.]\n",
            " [56.]\n",
            " [80.]\n",
            " [88.]]\n",
            "Returned from evaluate on test set...\n",
            "<class 'dict'>\n",
            "<built-in function bin>\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Run this cell to run main() function and fine-tune a BERT-based regressor\n",
        "\"\"\"\n",
        "\n",
        "                      #   Name           /Create encodings /Make dataset/Std Pts/Line breaks/Chunk\n",
        "methodologies = {0 : ('BERT First 512',\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "                      create_encodings, MakeTorchData, True, False, False),\n",
        "               #   1 : ('BERT Longformer 4096', \"allenai/longformer-base-4096\",\n",
        "               #        create_encodings, MakeTorchData, True, False, False)\n",
        "                    }\n",
        "\n",
        "train_batch_size = 16\n",
        "test_batch_size = 16\n",
        "save_label = \"BERT First 512\"\n",
        "max_length = 512\n",
        "\n",
        "# Training Arguments\n",
        "evaluation_strategy = 'epoch'\n",
        "save_strategy = 'epoch'\n",
        "save_total_limit = 1\n",
        "learning_rate = 5e-5\n",
        "per_device_train_batch_size = train_batch_size\n",
        "per_device_eval_batch_size = test_batch_size\n",
        "num_train_epochs = 10\n",
        "weight_decay = 0\n",
        "load_best_model_at_end = True\n",
        "metric_for_best_model = 'r2'\n",
        "\n",
        "main_args= {'methodologies' : methodologies,\n",
        "            'tokenizer' : tokenizer,\n",
        "            'save_label': save_label,\n",
        "            'max_length' : max_length,\n",
        "            'evaluation_strategy': evaluation_strategy,\n",
        "            'save_strategy' : save_strategy,\n",
        "            'save_total_limit' : save_total_limit,\n",
        "            'learning_rate' : learning_rate,\n",
        "            'per_device_train_batch_size' : per_device_train_batch_size,\n",
        "            'per_device_eval_batch_size' : per_device_eval_batch_size,\n",
        "            'num_train_epochs' : num_train_epochs,\n",
        "            'weight_decay': weight_decay,\n",
        "            'load_best_model_at_end' : load_best_model_at_end,\n",
        "            'metric_for_best_model' : metric_for_best_model}\n",
        "\n",
        "a, b = main(0, **main_args)\n",
        "\n",
        "\"\"\"\n",
        "Scroll down to cell below all this output to view \n",
        "performance metrics on validation and test datasets\n",
        "(a and b, respectively)\n",
        "\"\"\"    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGFtGlVSpkSw",
        "outputId": "5ab7b578-f5bb-4300-fa8e-8d7277bbb766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 73.21768951416016, 'eval_mse': 73.21768951416016, 'eval_var': 84.99159240722656, 'eval_r2': 0.13853022414011906, 'eval_accuracy': 0.06986899563318777, 'eval_runtime': 3.7872, 'eval_samples_per_second': 60.466, 'eval_steps_per_second': 3.961, 'epoch': 10.0}\n",
            "{'eval_loss': 76.2323989868164, 'eval_mse': 76.23239135742188, 'eval_var': 84.88729095458984, 'eval_r2': 0.1019574448215369, 'eval_accuracy': 0.07517482517482517, 'eval_runtime': 9.4004, 'eval_samples_per_second': 60.849, 'eval_steps_per_second': 3.83, 'epoch': 10.0}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(a)\n",
        "print(b)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0308fab4dcb448228e9b41ac53f64cb6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a704bc8e70c4780866ffeba8a325d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18acc9c0e6194cf2b5bb1010ae12ae02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35272d617bcf45dfac00420278eea79b",
            "placeholder": "​",
            "style": "IPY_MODEL_8a3755a65c004fec8b1b89340ece7533",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "19c1e6c6552845999c3a9cfde3e3d972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25cbc225f9e74d73921bde58a48510cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e480f9a5e94914af20f420e02e6f79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "281db7bc45fc4d4e8e0cfa4f2acf6b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29e928265c8f4c2fa983b4870d731910": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25cbc225f9e74d73921bde58a48510cc",
            "placeholder": "​",
            "style": "IPY_MODEL_19c1e6c6552845999c3a9cfde3e3d972",
            "value": " 629/629 [00:00&lt;00:00, 6.23kB/s]"
          }
        },
        "2f7b3fc1d1d74520a9437bc41461dde5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35272d617bcf45dfac00420278eea79b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d028338e0d4235a912c6564dac0235": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a8dda7dd2c747c18858fcf3129561c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c32f27667d824138b0f309f7596ee46c",
              "IPY_MODEL_b54616e138e5498c9a627863a87bd05e",
              "IPY_MODEL_29e928265c8f4c2fa983b4870d731910"
            ],
            "layout": "IPY_MODEL_d874fc6ba49f46b39fb92818ee5e5e82"
          }
        },
        "4ad49e41bf744450b81f3da81b01ee90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3ce84bad264a8bae525e22d11772c6",
            "placeholder": "​",
            "style": "IPY_MODEL_281db7bc45fc4d4e8e0cfa4f2acf6b05",
            "value": " 226k/226k [00:00&lt;00:00, 554kB/s]"
          }
        },
        "51d38bf4df404b2f86bb33db43fa6bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26e480f9a5e94914af20f420e02e6f79",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65e1d8e4d0c74ab1ae9f6b409bd7989f",
            "value": 48
          }
        },
        "5675bd10fe874e239c974677b5cef207": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65e1d8e4d0c74ab1ae9f6b409bd7989f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "693c9e7b5b7f419bb6f23fad55a87e7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a3755a65c004fec8b1b89340ece7533": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9816859db7434245950a92c72e9f7e56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3ce84bad264a8bae525e22d11772c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ece9fc77a5941f4b0e0f444fbf753d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9816859db7434245950a92c72e9f7e56",
            "placeholder": "​",
            "style": "IPY_MODEL_f5d997cc7dd54d91adb12cf14939643b",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "9feaf92695eb4eb793d6262958c9bdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ece9fc77a5941f4b0e0f444fbf753d0",
              "IPY_MODEL_e2105eefe33a4646b8774da10082c45c",
              "IPY_MODEL_4ad49e41bf744450b81f3da81b01ee90"
            ],
            "layout": "IPY_MODEL_44d028338e0d4235a912c6564dac0235"
          }
        },
        "b37851f63a68496e8826f326294f858b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0308fab4dcb448228e9b41ac53f64cb6",
            "placeholder": "​",
            "style": "IPY_MODEL_bca8269cdc4c433aa419a683a7d960d1",
            "value": " 48.0/48.0 [00:00&lt;00:00, 964B/s]"
          }
        },
        "b54616e138e5498c9a627863a87bd05e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5675bd10fe874e239c974677b5cef207",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b58160dfaab9450da3b1a8c1f147f8b1",
            "value": 629
          }
        },
        "b58160dfaab9450da3b1a8c1f147f8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bca8269cdc4c433aa419a683a7d960d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c32f27667d824138b0f309f7596ee46c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7b3fc1d1d74520a9437bc41461dde5",
            "placeholder": "​",
            "style": "IPY_MODEL_693c9e7b5b7f419bb6f23fad55a87e7b",
            "value": "Downloading config.json: 100%"
          }
        },
        "d3d23b23216148d785929cd0e324bd1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18acc9c0e6194cf2b5bb1010ae12ae02",
              "IPY_MODEL_51d38bf4df404b2f86bb33db43fa6bf7",
              "IPY_MODEL_b37851f63a68496e8826f326294f858b"
            ],
            "layout": "IPY_MODEL_e9514eb50be94889a042e50b460c02e4"
          }
        },
        "d79fb131a3064523b87759729d6af229": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d874fc6ba49f46b39fb92818ee5e5e82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2105eefe33a4646b8774da10082c45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d79fb131a3064523b87759729d6af229",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a704bc8e70c4780866ffeba8a325d25",
            "value": 231508
          }
        },
        "e9514eb50be94889a042e50b460c02e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d997cc7dd54d91adb12cf14939643b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
